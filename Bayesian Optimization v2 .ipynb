{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "# Modeling\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['font.size'] = 18\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EVALS = 20\n",
    "N_FOLDS = 5\n",
    "OUT_FILE = 'bayes_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 580)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = pd.read_csv('./preprocessed_data/all_data_v3.csv')\n",
    "original_data = original_data[original_data['TARGET'].notnull()]\n",
    "print(original_data.shape)\n",
    "\n",
    "# Sample 16000 rows (10000 for training, 6000 for testing)\n",
    "# features = original_data.sample(n = 16000, random_state = 42)\n",
    "\n",
    "features = original_data\n",
    "\n",
    "del original_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 703)\n"
     ]
    }
   ],
   "source": [
    "features = pd.get_dummies(features)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (301511, 701)\n",
      "Test shape:  (6000, 701)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>...</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_FRIDAY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_MONDAY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_SATURDAY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_SUNDAY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_THURSDAY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_TUESDAY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_WEDNESDAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193071</th>\n",
       "      <td>22797.0</td>\n",
       "      <td>215865.0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302257</th>\n",
       "      <td>34596.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263273</th>\n",
       "      <td>31531.5</td>\n",
       "      <td>485640.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68522</th>\n",
       "      <td>16879.5</td>\n",
       "      <td>552555.0</td>\n",
       "      <td>477000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6848</th>\n",
       "      <td>35577.0</td>\n",
       "      <td>665325.0</td>\n",
       "      <td>616500.0</td>\n",
       "      <td>139500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AMT_ANNUITY  AMT_CREDIT  AMT_GOODS_PRICE  AMT_INCOME_TOTAL  \\\n",
       "193071      22797.0    215865.0         202500.0          247500.0   \n",
       "302257      34596.0    675000.0         675000.0          180000.0   \n",
       "263273      31531.5    485640.0         450000.0          202500.0   \n",
       "68522       16879.5    552555.0         477000.0          180000.0   \n",
       "6848        35577.0    665325.0         616500.0          139500.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "193071                        0.0                         0.0   \n",
       "302257                        0.0                         0.0   \n",
       "263273                        0.0                         0.0   \n",
       "68522                         0.0                         0.0   \n",
       "6848                          0.0                         0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "193071                        0.0                        0.0   \n",
       "302257                        0.0                        0.0   \n",
       "263273                        0.0                        1.0   \n",
       "68522                         0.0                        1.0   \n",
       "6848                          0.0                        1.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_YEAR  \\\n",
       "193071                         0.0                         2.0   \n",
       "302257                         0.0                         3.0   \n",
       "263273                         0.0                         4.0   \n",
       "68522                          0.0                         3.0   \n",
       "6848                           0.0                         3.0   \n",
       "\n",
       "                        ...                   WALLSMATERIAL_MODE_Panel  \\\n",
       "193071                  ...                                          0   \n",
       "302257                  ...                                          0   \n",
       "263273                  ...                                          1   \n",
       "68522                   ...                                          0   \n",
       "6848                    ...                                          0   \n",
       "\n",
       "        WALLSMATERIAL_MODE_Stone, brick  WALLSMATERIAL_MODE_Wooden  \\\n",
       "193071                                0                          0   \n",
       "302257                                0                          0   \n",
       "263273                                0                          0   \n",
       "68522                                 0                          0   \n",
       "6848                                  0                          0   \n",
       "\n",
       "        WEEKDAY_APPR_PROCESS_START_FRIDAY  WEEKDAY_APPR_PROCESS_START_MONDAY  \\\n",
       "193071                                  0                                  0   \n",
       "302257                                  1                                  0   \n",
       "263273                                  0                                  0   \n",
       "68522                                   1                                  0   \n",
       "6848                                    0                                  0   \n",
       "\n",
       "        WEEKDAY_APPR_PROCESS_START_SATURDAY  \\\n",
       "193071                                    0   \n",
       "302257                                    0   \n",
       "263273                                    0   \n",
       "68522                                     0   \n",
       "6848                                      0   \n",
       "\n",
       "        WEEKDAY_APPR_PROCESS_START_SUNDAY  \\\n",
       "193071                                  0   \n",
       "302257                                  0   \n",
       "263273                                  0   \n",
       "68522                                   0   \n",
       "6848                                    0   \n",
       "\n",
       "        WEEKDAY_APPR_PROCESS_START_THURSDAY  \\\n",
       "193071                                    0   \n",
       "302257                                    0   \n",
       "263273                                    1   \n",
       "68522                                     0   \n",
       "6848                                      1   \n",
       "\n",
       "        WEEKDAY_APPR_PROCESS_START_TUESDAY  \\\n",
       "193071                                   0   \n",
       "302257                                   0   \n",
       "263273                                   0   \n",
       "68522                                    0   \n",
       "6848                                     0   \n",
       "\n",
       "        WEEKDAY_APPR_PROCESS_START_WEDNESDAY  \n",
       "193071                                     1  \n",
       "302257                                     0  \n",
       "263273                                     0  \n",
       "68522                                      0  \n",
       "6848                                       0  \n",
       "\n",
       "[5 rows x 701 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the labels\n",
    "labels = np.array(features['TARGET'].astype(np.int32)).reshape((-1, ))\n",
    "features = features.drop(columns = ['TARGET', 'SK_ID_CURR'])\n",
    "\n",
    "# Split into training and testing data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 6000, random_state = 42)\n",
    "\n",
    "print('Train shape: ', train_features.shape)\n",
    "print('Test shape: ', test_features.shape)\n",
    "\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "train_set = lgb.Dataset(train_features, label = train_labels)\n",
    "test_set = lgb.Dataset(test_features, label = test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from hyperopt import STATUS_OK\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def objective(hyperparameters):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization.\n",
    "       Writes a new line to `outfile` on every iteration\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # Using early stopping to find number of trees trained\n",
    "    if 'n_estimators' in hyperparameters:\n",
    "        del hyperparameters['n_estimators']\n",
    "    \n",
    "    # Retrieve the subsample\n",
    "    subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type and subsample to top level keys\n",
    "    hyperparameters['boosting_type'] = hyperparameters['boosting_type']['boosting_type']\n",
    "    hyperparameters['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n",
    "\n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n",
    "                        verbose_eval = 100,early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "\n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = cv_results['auc-mean'][-1]\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = len(cv_results['auc-mean'])\n",
    "    \n",
    "    # Add the number of estimators to the hyperparameters\n",
    "    hyperparameters['n_estimators'] = n_estimators\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(OUT_FILE, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score])\n",
    "    of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "# Define the search space / domain\n",
    "space = {\n",
    "    'boosting_type': hp.choice('boosting_type', \n",
    "                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                             {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                             {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "    'is_unbalance': hp.choice('is_unbalance', [True, False]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe\n",
    "\n",
    "# Create the optimization algorithm\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials\n",
    "\n",
    "# Record results\n",
    "trials = Trials()\n",
    "\n",
    "# Create a file and open a connection\n",
    "# OUT_FILE = 'bayes_test.csv'\n",
    "of_connection = open(OUT_FILE, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Write column names\n",
    "headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin\n",
    "\n",
    "ITERATION = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's auc: 0.775761 + 0.00418196\n",
      "[200]\tcv_agg's auc: 0.782736 + 0.0039623\n",
      "[300]\tcv_agg's auc: 0.783862 + 0.00405168\n",
      "[400]\tcv_agg's auc: 0.783599 + 0.00423582\n",
      "[100]\tcv_agg's auc: 0.511255 + 0.035303\n",
      "[100]\tcv_agg's auc: 0.490009 + 0.0272143\n",
      "[100]\tcv_agg's auc: 0.770454 + 0.00438771\n",
      "[200]\tcv_agg's auc: 0.776033 + 0.00426206\n",
      "[300]\tcv_agg's auc: 0.780462 + 0.00399788\n",
      "[400]\tcv_agg's auc: 0.782802 + 0.00471015\n",
      "[500]\tcv_agg's auc: 0.784995 + 0.00434118\n",
      "[600]\tcv_agg's auc: 0.785084 + 0.00394281\n",
      "[100]\tcv_agg's auc: 0.764318 + 0.00429067\n",
      "[200]\tcv_agg's auc: 0.769898 + 0.00458559\n",
      "[300]\tcv_agg's auc: 0.774728 + 0.00463329\n",
      "[400]\tcv_agg's auc: 0.778171 + 0.00439136\n",
      "[500]\tcv_agg's auc: 0.781706 + 0.0042223\n",
      "[600]\tcv_agg's auc: 0.78268 + 0.00421134\n",
      "[700]\tcv_agg's auc: 0.783662 + 0.00415979\n",
      "[800]\tcv_agg's auc: 0.784521 + 0.00389257\n",
      "[900]\tcv_agg's auc: 0.78493 + 0.00388384\n",
      "[1000]\tcv_agg's auc: 0.785345 + 0.00385552\n",
      "[1100]\tcv_agg's auc: 0.785433 + 0.00402358\n",
      "[100]\tcv_agg's auc: 0.49697 + 0.0557592\n",
      "[100]\tcv_agg's auc: 0.774555 + 0.00461269\n",
      "[200]\tcv_agg's auc: 0.78356 + 0.00408191\n",
      "[300]\tcv_agg's auc: 0.786192 + 0.00386592\n",
      "[400]\tcv_agg's auc: 0.786512 + 0.00350166\n",
      "[500]\tcv_agg's auc: 0.786327 + 0.00336478\n",
      "[100]\tcv_agg's auc: 0.752965 + 0.00469212\n",
      "[200]\tcv_agg's auc: 0.763158 + 0.00480439\n",
      "[300]\tcv_agg's auc: 0.770901 + 0.00472235\n",
      "[400]\tcv_agg's auc: 0.776011 + 0.00451947\n",
      "[500]\tcv_agg's auc: 0.779298 + 0.0043983\n",
      "[600]\tcv_agg's auc: 0.78158 + 0.0043848\n",
      "[700]\tcv_agg's auc: 0.783206 + 0.00438496\n",
      "[800]\tcv_agg's auc: 0.784469 + 0.00440812\n",
      "[900]\tcv_agg's auc: 0.78537 + 0.00430446\n",
      "[1000]\tcv_agg's auc: 0.786039 + 0.00427696\n",
      "[1100]\tcv_agg's auc: 0.786494 + 0.00430299\n",
      "[1200]\tcv_agg's auc: 0.786901 + 0.00429751\n",
      "[1300]\tcv_agg's auc: 0.787194 + 0.00431285\n",
      "[1400]\tcv_agg's auc: 0.787462 + 0.0042391\n",
      "[1500]\tcv_agg's auc: 0.787632 + 0.00420291\n",
      "[1600]\tcv_agg's auc: 0.787776 + 0.00416345\n",
      "[1700]\tcv_agg's auc: 0.787896 + 0.00417627\n",
      "[1800]\tcv_agg's auc: 0.788019 + 0.00411439\n",
      "[1900]\tcv_agg's auc: 0.788058 + 0.00410454\n",
      "[2000]\tcv_agg's auc: 0.788124 + 0.0040472\n",
      "[2100]\tcv_agg's auc: 0.788092 + 0.00403083\n",
      "[100]\tcv_agg's auc: 0.755386 + 0.00462057\n",
      "[200]\tcv_agg's auc: 0.761088 + 0.00471636\n",
      "[300]\tcv_agg's auc: 0.767127 + 0.00482884\n",
      "[400]\tcv_agg's auc: 0.771458 + 0.00476582\n",
      "[500]\tcv_agg's auc: 0.775725 + 0.00477984\n",
      "[600]\tcv_agg's auc: 0.777468 + 0.00473043\n",
      "[700]\tcv_agg's auc: 0.77867 + 0.00463474\n",
      "[800]\tcv_agg's auc: 0.779971 + 0.00468721\n",
      "[900]\tcv_agg's auc: 0.781335 + 0.00457627\n",
      "[1000]\tcv_agg's auc: 0.782157 + 0.00446023\n",
      "[1100]\tcv_agg's auc: 0.782982 + 0.00452957\n",
      "[1200]\tcv_agg's auc: 0.783213 + 0.00447066\n",
      "[1300]\tcv_agg's auc: 0.783747 + 0.00455871\n",
      "[1400]\tcv_agg's auc: 0.784609 + 0.0045774\n",
      "[1500]\tcv_agg's auc: 0.784796 + 0.00441012\n",
      "[1600]\tcv_agg's auc: 0.785063 + 0.00450573\n",
      "[1700]\tcv_agg's auc: 0.785662 + 0.00440493\n",
      "[1800]\tcv_agg's auc: 0.786198 + 0.004383\n",
      "[1900]\tcv_agg's auc: 0.786419 + 0.00432846\n",
      "[2000]\tcv_agg's auc: 0.786422 + 0.00428376\n",
      "[2100]\tcv_agg's auc: 0.786815 + 0.00415567\n",
      "[2200]\tcv_agg's auc: 0.786952 + 0.00403551\n",
      "[2300]\tcv_agg's auc: 0.787188 + 0.00397816\n",
      "[2400]\tcv_agg's auc: 0.787384 + 0.00388123\n",
      "[2500]\tcv_agg's auc: 0.787206 + 0.00384914\n",
      "[100]\tcv_agg's auc: 0.774891 + 0.00488215\n",
      "[200]\tcv_agg's auc: 0.778973 + 0.00461229\n",
      "[300]\tcv_agg's auc: 0.780001 + 0.00423352\n",
      "[400]\tcv_agg's auc: 0.779566 + 0.0041698\n",
      "[100]\tcv_agg's auc: 0.474763 + 0.0338173\n",
      "[100]\tcv_agg's auc: 0.758013 + 0.00418734\n",
      "[200]\tcv_agg's auc: 0.767442 + 0.00467435\n",
      "[300]\tcv_agg's auc: 0.774851 + 0.00434903\n",
      "[400]\tcv_agg's auc: 0.779414 + 0.00402372\n",
      "[500]\tcv_agg's auc: 0.782301 + 0.00391137\n",
      "[600]\tcv_agg's auc: 0.784109 + 0.00386458\n",
      "[700]\tcv_agg's auc: 0.785295 + 0.00374293\n",
      "[800]\tcv_agg's auc: 0.78605 + 0.00376215\n",
      "[900]\tcv_agg's auc: 0.786486 + 0.00373339\n",
      "[1000]\tcv_agg's auc: 0.786833 + 0.00377116\n",
      "[1100]\tcv_agg's auc: 0.78698 + 0.00385878\n",
      "[1200]\tcv_agg's auc: 0.787063 + 0.00395468\n",
      "[100]\tcv_agg's auc: 0.77302 + 0.00413744\n",
      "[200]\tcv_agg's auc: 0.771904 + 0.00336085\n",
      "[100]\tcv_agg's auc: 0.489118 + 0.0486762\n",
      "[100]\tcv_agg's auc: 0.75886 + 0.00424046\n",
      "[100]\tcv_agg's auc: 0.770106 + 0.0047992\n",
      "[200]\tcv_agg's auc: 0.775533 + 0.00457488\n",
      "[300]\tcv_agg's auc: 0.78051 + 0.00455368\n",
      "[400]\tcv_agg's auc: 0.782949 + 0.00433736\n",
      "[500]\tcv_agg's auc: 0.784315 + 0.00455079\n",
      "[600]\tcv_agg's auc: 0.784192 + 0.00420309\n",
      "[100]\tcv_agg's auc: 0.763626 + 0.00444582\n",
      "[200]\tcv_agg's auc: 0.769251 + 0.00444101\n",
      "[300]\tcv_agg's auc: 0.774029 + 0.00466385\n",
      "[400]\tcv_agg's auc: 0.777333 + 0.00452563\n",
      "[500]\tcv_agg's auc: 0.780727 + 0.00433035\n",
      "[600]\tcv_agg's auc: 0.782053 + 0.00421324\n",
      "[700]\tcv_agg's auc: 0.782595 + 0.00395426\n",
      "[800]\tcv_agg's auc: 0.783113 + 0.00413513\n",
      "[900]\tcv_agg's auc: 0.783882 + 0.00394141\n",
      "[1000]\tcv_agg's auc: 0.784164 + 0.00375992\n",
      "[1100]\tcv_agg's auc: 0.78434 + 0.00368832\n",
      "[1200]\tcv_agg's auc: 0.78439 + 0.00367116\n",
      "[1300]\tcv_agg's auc: 0.784483 + 0.00374583\n",
      "[1400]\tcv_agg's auc: 0.785009 + 0.0035918\n",
      "[1500]\tcv_agg's auc: 0.784981 + 0.00356282\n",
      "[100]\tcv_agg's auc: 0.777637 + 0.0040316\n",
      "[200]\tcv_agg's auc: 0.783777 + 0.0034502\n",
      "[300]\tcv_agg's auc: 0.784689 + 0.00339407\n",
      "[400]\tcv_agg's auc: 0.783976 + 0.00331652\n",
      "[100]\tcv_agg's auc: 0.763888 + 0.00475902\n",
      "[200]\tcv_agg's auc: 0.775161 + 0.00454304\n",
      "[300]\tcv_agg's auc: 0.779833 + 0.00447745\n",
      "[400]\tcv_agg's auc: 0.782416 + 0.00442008\n",
      "[500]\tcv_agg's auc: 0.783867 + 0.0044226\n",
      "[600]\tcv_agg's auc: 0.78467 + 0.0042856\n",
      "[700]\tcv_agg's auc: 0.785166 + 0.00403128\n",
      "[800]\tcv_agg's auc: 0.785633 + 0.00404784\n",
      "[900]\tcv_agg's auc: 0.785978 + 0.00403456\n",
      "[1000]\tcv_agg's auc: 0.786244 + 0.0039542\n",
      "[1100]\tcv_agg's auc: 0.786291 + 0.00393513\n",
      "[1200]\tcv_agg's auc: 0.78629 + 0.00393019\n",
      "[100]\tcv_agg's auc: 0.765669 + 0.00489312\n",
      "[200]\tcv_agg's auc: 0.777148 + 0.00428721\n",
      "[300]\tcv_agg's auc: 0.781398 + 0.0042708\n",
      "[400]\tcv_agg's auc: 0.783441 + 0.00403224\n",
      "[500]\tcv_agg's auc: 0.7845 + 0.00407672\n",
      "[600]\tcv_agg's auc: 0.785092 + 0.00411127\n",
      "[700]\tcv_agg's auc: 0.785316 + 0.00436544\n",
      "[800]\tcv_agg's auc: 0.785323 + 0.00431274\n",
      "CPU times: user 1d 21h 7min 13s, sys: 16min 8s, total: 1d 21h 23min 21s\n",
      "Wall time: 11h 37min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n",
    "            max_evals = MAX_EVALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 0,\n",
       " 'colsample_by_tree': 0.7157128140557183,\n",
       " 'gdbt_subsample': 0.8704264554232746,\n",
       " 'is_unbalance': 0,\n",
       " 'learning_rate': 0.010895675526704639,\n",
       " 'min_child_samples': 245.0,\n",
       " 'num_leaves': 54.0,\n",
       " 'reg_alpha': 0.7277077790414211,\n",
       " 'reg_lambda': 0.12196456631794106,\n",
       " 'subsample_for_bin': 140000.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def evaluate(results, name):\n",
    "    \"\"\"Evaluate model on test data using hyperparameters in results\n",
    "       Return dataframe of hyperparameters\"\"\"\n",
    "    \n",
    "    new_results = results.copy()\n",
    "    # String to dictionary\n",
    "    new_results['hyperparameters'] = new_results['hyperparameters'].map(ast.literal_eval)\n",
    "    \n",
    "    # Sort with best values on top\n",
    "    new_results = new_results.sort_values('score', ascending = False).reset_index(drop = True)\n",
    "    \n",
    "    # Print out cross validation high score\n",
    "    print('The highest cross validation score from {} was {:.5f} found on iteration {}.'.format(name, new_results.loc[0, 'score'], new_results.loc[0, 'iteration']))\n",
    "    \n",
    "    # Use best hyperparameters to create a model\n",
    "    hyperparameters = new_results.loc[0, 'hyperparameters']\n",
    "    model = lgb.LGBMClassifier(**hyperparameters)\n",
    "    \n",
    "    # Train and make predictions\n",
    "    model.fit(train_features, train_labels)\n",
    "    preds = model.predict_proba(test_features)[:, 1]\n",
    "    \n",
    "    print('ROC AUC from {} on test data = {:.5f}.'.format(name, roc_auc_score(test_labels, preds)))\n",
    "    \n",
    "    # Create dataframe of hyperparameters\n",
    "    hyp_df = pd.DataFrame(columns = list(new_results.loc[0, 'hyperparameters'].keys()))\n",
    "\n",
    "    # Iterate through each set of hyperparameters that were evaluated\n",
    "    for i, hyp in enumerate(new_results['hyperparameters']):\n",
    "        hyp_df = hyp_df.append(pd.DataFrame(hyp, index = [0]), \n",
    "                               ignore_index = True)\n",
    "        \n",
    "    # Put the iteration and score in the hyperparameter dataframe\n",
    "    hyp_df['iteration'] = new_results['iteration']\n",
    "    hyp_df['score'] = new_results['score']\n",
    "    \n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "    return hyp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest cross validation score from Bayesian was 0.78812 found on iteration 8.\n",
      "ROC AUC from Bayesian on test data = 0.78526.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>is_unbalance</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <th>subsample</th>\n",
       "      <th>metric</th>\n",
       "      <th>verbose</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>iteration</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.715713</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>245</td>\n",
       "      <td>54</td>\n",
       "      <td>0.727708</td>\n",
       "      <td>0.121965</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.870426</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>0.788124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.758440</td>\n",
       "      <td>False</td>\n",
       "      <td>0.028614</td>\n",
       "      <td>270</td>\n",
       "      <td>54</td>\n",
       "      <td>0.140301</td>\n",
       "      <td>0.582904</td>\n",
       "      <td>240000</td>\n",
       "      <td>0.994368</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>2404</td>\n",
       "      <td>9</td>\n",
       "      <td>0.787395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.925477</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>150</td>\n",
       "      <td>145</td>\n",
       "      <td>0.419077</td>\n",
       "      <td>0.963646</td>\n",
       "      <td>240000</td>\n",
       "      <td>0.643987</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>1195</td>\n",
       "      <td>12</td>\n",
       "      <td>0.787069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.630376</td>\n",
       "      <td>False</td>\n",
       "      <td>0.028166</td>\n",
       "      <td>435</td>\n",
       "      <td>124</td>\n",
       "      <td>0.289069</td>\n",
       "      <td>0.088868</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.672921</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>450</td>\n",
       "      <td>7</td>\n",
       "      <td>0.786662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.632092</td>\n",
       "      <td>False</td>\n",
       "      <td>0.030250</td>\n",
       "      <td>125</td>\n",
       "      <td>24</td>\n",
       "      <td>0.392897</td>\n",
       "      <td>0.030363</td>\n",
       "      <td>220000</td>\n",
       "      <td>0.530251</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>19</td>\n",
       "      <td>0.786357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.756598</td>\n",
       "      <td>False</td>\n",
       "      <td>0.030221</td>\n",
       "      <td>395</td>\n",
       "      <td>132</td>\n",
       "      <td>0.116008</td>\n",
       "      <td>0.601984</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.766222</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>1045</td>\n",
       "      <td>5</td>\n",
       "      <td>0.785539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>False</td>\n",
       "      <td>0.026128</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>0.723469</td>\n",
       "      <td>0.786496</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.532487</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>732</td>\n",
       "      <td>20</td>\n",
       "      <td>0.785413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.658995</td>\n",
       "      <td>True</td>\n",
       "      <td>0.048186</td>\n",
       "      <td>405</td>\n",
       "      <td>143</td>\n",
       "      <td>0.064139</td>\n",
       "      <td>0.973434</td>\n",
       "      <td>240000</td>\n",
       "      <td>0.857503</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>571</td>\n",
       "      <td>4</td>\n",
       "      <td>0.785317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.655189</td>\n",
       "      <td>False</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>220</td>\n",
       "      <td>146</td>\n",
       "      <td>0.983310</td>\n",
       "      <td>0.458931</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.763076</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>1462</td>\n",
       "      <td>17</td>\n",
       "      <td>0.785033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.974536</td>\n",
       "      <td>True</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>335</td>\n",
       "      <td>149</td>\n",
       "      <td>0.280880</td>\n",
       "      <td>0.809136</td>\n",
       "      <td>280000</td>\n",
       "      <td>0.879373</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>18</td>\n",
       "      <td>0.784838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.780150</td>\n",
       "      <td>False</td>\n",
       "      <td>0.067047</td>\n",
       "      <td>160</td>\n",
       "      <td>119</td>\n",
       "      <td>0.707560</td>\n",
       "      <td>0.847574</td>\n",
       "      <td>260000</td>\n",
       "      <td>0.627311</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>506</td>\n",
       "      <td>16</td>\n",
       "      <td>0.784377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.961591</td>\n",
       "      <td>True</td>\n",
       "      <td>0.043551</td>\n",
       "      <td>115</td>\n",
       "      <td>87</td>\n",
       "      <td>0.460248</td>\n",
       "      <td>0.025232</td>\n",
       "      <td>240000</td>\n",
       "      <td>0.841647</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.783866</td>\n",
       "      <td>True</td>\n",
       "      <td>0.151505</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>0.535882</td>\n",
       "      <td>0.446603</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.705675</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>334</td>\n",
       "      <td>10</td>\n",
       "      <td>0.780243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.853717</td>\n",
       "      <td>True</td>\n",
       "      <td>0.243504</td>\n",
       "      <td>90</td>\n",
       "      <td>98</td>\n",
       "      <td>0.525647</td>\n",
       "      <td>0.156363</td>\n",
       "      <td>240000</td>\n",
       "      <td>0.740945</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>13</td>\n",
       "      <td>0.774292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.977569</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366017</td>\n",
       "      <td>335</td>\n",
       "      <td>132</td>\n",
       "      <td>0.257881</td>\n",
       "      <td>0.502029</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.577007</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.762669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.747956</td>\n",
       "      <td>False</td>\n",
       "      <td>0.137371</td>\n",
       "      <td>315</td>\n",
       "      <td>108</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.179178</td>\n",
       "      <td>20000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.753907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.692630</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>370</td>\n",
       "      <td>66</td>\n",
       "      <td>0.530632</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.752913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.873281</td>\n",
       "      <td>False</td>\n",
       "      <td>0.160486</td>\n",
       "      <td>295</td>\n",
       "      <td>114</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.477047</td>\n",
       "      <td>280000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.751787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.781394</td>\n",
       "      <td>True</td>\n",
       "      <td>0.013753</td>\n",
       "      <td>125</td>\n",
       "      <td>37</td>\n",
       "      <td>0.744437</td>\n",
       "      <td>0.735531</td>\n",
       "      <td>200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>0.748443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.652870</td>\n",
       "      <td>True</td>\n",
       "      <td>0.107309</td>\n",
       "      <td>465</td>\n",
       "      <td>39</td>\n",
       "      <td>0.893824</td>\n",
       "      <td>0.888521</td>\n",
       "      <td>60000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.747584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   boosting_type  colsample_bytree is_unbalance  learning_rate  \\\n",
       "0           gbdt          0.715713         True       0.010896   \n",
       "1           dart          0.758440        False       0.028614   \n",
       "2           gbdt          0.925477        False       0.010638   \n",
       "3           gbdt          0.630376        False       0.028166   \n",
       "4           gbdt          0.632092        False       0.030250   \n",
       "5           dart          0.756598        False       0.030221   \n",
       "6           gbdt          0.774411        False       0.026128   \n",
       "7           dart          0.658995         True       0.048186   \n",
       "8           dart          0.655189        False       0.030459   \n",
       "9           gbdt          0.974536         True       0.034986   \n",
       "10          dart          0.780150        False       0.067047   \n",
       "11          gbdt          0.961591         True       0.043551   \n",
       "12          dart          0.783866         True       0.151505   \n",
       "13          dart          0.853717         True       0.243504   \n",
       "14          dart          0.977569        False       0.366017   \n",
       "15          goss          0.747956        False       0.137371   \n",
       "16          goss          0.692630         True       0.047469   \n",
       "17          goss          0.873281        False       0.160486   \n",
       "18          goss          0.781394         True       0.013753   \n",
       "19          goss          0.652870         True       0.107309   \n",
       "\n",
       "   min_child_samples num_leaves  reg_alpha  reg_lambda subsample_for_bin  \\\n",
       "0                245         54   0.727708    0.121965            140000   \n",
       "1                270         54   0.140301    0.582904            240000   \n",
       "2                150        145   0.419077    0.963646            240000   \n",
       "3                435        124   0.289069    0.088868            100000   \n",
       "4                125         24   0.392897    0.030363            220000   \n",
       "5                395        132   0.116008    0.601984            160000   \n",
       "6                 55         62   0.723469    0.786496            140000   \n",
       "7                405        143   0.064139    0.973434            240000   \n",
       "8                220        146   0.983310    0.458931            100000   \n",
       "9                335        149   0.280880    0.809136            280000   \n",
       "10               160        119   0.707560    0.847574            260000   \n",
       "11               115         87   0.460248    0.025232            240000   \n",
       "12                35         56   0.535882    0.446603             40000   \n",
       "13                90         98   0.525647    0.156363            240000   \n",
       "14               335        132   0.257881    0.502029             80000   \n",
       "15               315        108   0.136600    0.179178             20000   \n",
       "16               370         66   0.530632    0.602740            200000   \n",
       "17               295        114   0.000905    0.477047            280000   \n",
       "18               125         37   0.744437    0.735531            200000   \n",
       "19               465         39   0.893824    0.888521             60000   \n",
       "\n",
       "    subsample metric verbose n_estimators  iteration     score  \n",
       "0    0.870426    auc       1         2002          8  0.788124  \n",
       "1    0.994368    auc       1         2404          9  0.787395  \n",
       "2    0.643987    auc       1         1195         12  0.787069  \n",
       "3    0.672921    auc       1          450          7  0.786662  \n",
       "4    0.530251    auc       1         1169         19  0.786357  \n",
       "5    0.766222    auc       1         1045          5  0.785539  \n",
       "6    0.532487    auc       1          732         20  0.785413  \n",
       "7    0.857503    auc       1          571          4  0.785317  \n",
       "8    0.763076    auc       1         1462         17  0.785033  \n",
       "9    0.879373    auc       1          320         18  0.784838  \n",
       "10   0.627311    auc       1          506         16  0.784377  \n",
       "11   0.841647    auc       1          307          1  0.783925  \n",
       "12   0.705675    auc       1          334         10  0.780243  \n",
       "13   0.740945    auc       1          160         13  0.774292  \n",
       "14   0.577007    auc       1           15         15  0.762669  \n",
       "15   1.000000    auc       1            7         11  0.753907  \n",
       "16   1.000000    auc       1           21          2  0.752913  \n",
       "17   1.000000    auc       1            6         14  0.751787  \n",
       "18   1.000000    auc       1           72          6  0.748443  \n",
       "19   1.000000    auc       1            9          3  0.747584  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(OUT_FILE)\n",
    "bayes_results = evaluate(results, name = 'Bayesian')\n",
    "bayes_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue Optimization\n",
    "Hyperopt can continue searching where a previous search left off if we pass in a Trials object that already has results. The algorithms used in Bayesian optimization are black-box optimizers because they have no internal state. All they need is the previous results of objective function evaluations (the input values and loss) and they can build up the surrogate function and select the next values to evaluate in the objective function. This means that any search can be continued as long as we have the history in a Trials object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trials_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a8089e677755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Save the trial results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trials.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trials_dict' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "trials_dict = sorted(trials.results, key = lambda x: x['loss'])\n",
    "\n",
    "# Save the trial results\n",
    "with open('trials.json', 'w') as f:\n",
    "    f.write(json.dumps(trials_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boosting_type             gbdt\n",
       "colsample_bytree      0.715713\n",
       "is_unbalance              True\n",
       "learning_rate        0.0108957\n",
       "min_child_samples          245\n",
       "num_leaves                  54\n",
       "reg_alpha             0.727708\n",
       "reg_lambda            0.121965\n",
       "subsample_for_bin       140000\n",
       "subsample             0.870426\n",
       "metric                     auc\n",
       "verbose                      1\n",
       "n_estimators              2002\n",
       "iteration                    8\n",
       "score                 0.788124\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bayes_params = bayes_results.iloc[bayes_results['score'].idxmax(), :].copy()\n",
    "best_bayes_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.7157128140557183,\n",
       " 'is_unbalance': True,\n",
       " 'learning_rate': 0.010895675526704639,\n",
       " 'min_child_samples': 245,\n",
       " 'num_leaves': 54,\n",
       " 'reg_alpha': 0.7277077790414211,\n",
       " 'reg_lambda': 0.12196456631794106,\n",
       " 'subsample_for_bin': 140000,\n",
       " 'subsample': 0.8704264554232746,\n",
       " 'metric': 'auc',\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = dict(best_bayes_params)\n",
    "del_keys = ['n_estimators','iteration','score']\n",
    "for key in del_keys:\n",
    "    del hyperparameters[key]\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters =   {'boosting_type': 'gbdt',\n",
    "                     'objective': 'binary',\n",
    "                     'number_boosting_rounds': 5000,\n",
    "                     'early_stopping_rounds': 100,\n",
    "                     'max_bin': 300,\n",
    "                     'max_depth': -1,\n",
    "                     'num_leaves': 35,\n",
    "                     'learning_rate': 0.1,\n",
    "                     'subsample': 1,\n",
    "                     'min_child_samples': 50,\n",
    "                     'subsample_freq': 1,\n",
    "                     'min_gain_to_split': 0.5,\n",
    "                     'scale_pos_weight': 1,\n",
    "                     'colsample_bytree': 0.2,\n",
    "                     'is_unbalance': True,\n",
    "                     'reg_alpha': 0.0,\n",
    "                     'reg_lambda': 100,\n",
    "                     'metric': 'auc',\n",
    "                     'verbose': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_set, test_set\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (307511, 699)\n",
      "Testing shape:  (48744, 699)\n"
     ]
    }
   ],
   "source": [
    "# train = pd.read_csv('./preprocessed_data/train_v2.csv')\n",
    "# test = pd.read_csv('./preprocessed_data/test_v2.csv')\n",
    "\n",
    "original_data = pd.read_csv('./preprocessed_data/all_data_v3.csv')\n",
    "train = original_data[original_data['TARGET'].notnull()]\n",
    "test = original_data[original_data['TARGET'].isnull()]\n",
    "\n",
    "# train = pd.get_dummies(train)\n",
    "# test = pd.get_dummies(test)\n",
    "\n",
    "del original_data\n",
    "gc.collect()\n",
    "\n",
    "# Extract the test ids and train labels\n",
    "test_ids = test['SK_ID_CURR']\n",
    "train_labels = np.array(train['TARGET'].astype(np.int32)).reshape((-1, ))\n",
    "\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "train,test = train.align(test, join = 'inner', axis = 1)\n",
    "\n",
    "train = train.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "test = test.drop(columns = ['SK_ID_CURR','TARGET'])\n",
    "\n",
    "\n",
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lizihaoleo/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:399: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation score on the full dataset for Bayesian optimization = 0.78757 with std: 0.00282.\n",
      "Number of estimators = 272.\n"
     ]
    }
   ],
   "source": [
    "train_set = lgb.Dataset(train, label = train_labels,categorical_feature='auto')\n",
    "\n",
    "# Cross validation with n_folds and early stopping\n",
    "cv_results = lgb.cv(hyperparameters, train_set,\n",
    "                    num_boost_round = 10000, early_stopping_rounds = 100, \n",
    "                    metrics = 'auc', nfold = N_FOLDS)\n",
    "\n",
    "print('The cross validation score on the full dataset for Bayesian optimization = {:.5f} with std: {:.5f}.'.format(\n",
    "    cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\n",
    "print('Number of estimators = {}.'.format(len(cv_results['auc-mean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lgb.LGBMClassifier(n_estimators = len(cv_results['auc-mean']), **hyperparameters)\n",
    "model = lgb.LGBMClassifier( **hyperparameters)\n",
    "model.fit(train, train_labels)\n",
    "\n",
    "preds = model.predict_proba(test)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': preds})\n",
    "submission.to_csv('./model_performance/bo_v3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pred, Target]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_fold_pd = pd.DataFrame(columns=['pred','Target'])\n",
    "out_of_fold_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [ 1 , 0, 1]\n",
    "target = [1, 0, 1]\n",
    "tmp = pd.DataFrame(data={'pred': pred, 'Target': target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pred Target\n",
       "0    1      1\n",
       "1    0      0\n",
       "2    1      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_fold_pd.append(tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
